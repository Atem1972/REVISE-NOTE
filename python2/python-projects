
## project 01 
              Script modification ticket: this script is used by your team to check endpoints but will throw an error when the URL doesn't have HTTP so we need to add an exception for that to avoid code-breaking when the URL is not good. (For example, google.com won't work but http://google.com will.)

              #Program to fetch the http status code give the url/api
from urllib.request import urlopen
from urllib.error import URLError, HTTPError

#Taking input url from user
requestURL = input("Enter the URL: ")

#Gets the response from URL and prints the status code, corresponding emoji and message accordingly
try:
    response = urlopen(requestURL)
    #In case of success, prints success status code
    print('Status code : ' + str(response.code))
    print('Message : ' + 'Request succeeded. Request returned message - ' + response.reason)
except HTTPError as e:
    #In case of request failure, prints HTTP error status code
    print('Status : ' + str(e.code) )
    print('Message : Request failed. Request returned reason - ' + e.reason)
except URLError as e:
    #In case of bad URL or connection failure, prints Win Error
    print('Status :',  str(e.reason).split(']')[0].replace('[','') )
    print('Message : '+ str(e.reason).split(']')[1])
except ValueError:
    print("Malformed URL, please check again !!!")


## 02 project 
         We have a script that we use to generate QR codes. It needs two inputs the message/URL and the file name for the QR code. Please look at how to use the argparse module to set it in a way that we can run it with arguments and provide those inputs. -h or --help should show how to use the script, -u or --url should be used to provide the URL and -i or --im should be used to provide the file image name.

# install pyqrcode and pypng
import pyqrcode
import png
from pyqrcode import QRCode

# Text which is to be converted to QR code
text_to_convert=input("Enter text to convert: ")
# Name of QR code png file
image_name=input("Enter image name to save: ")
# Adding extension as .pnf
file_name=image_name+".png"
# Creating QR code
url=pyqrcode.create(text_to_convert)
# Saving QR code as  a png file
url.show()
url.png(file_name, scale =6)


## 03 project 
   At work, there is a need for a python script that can convert .xml files to JSON format. To execute this script, we took "test.xml" file as an example. We can get that file from the current directory.

   # install json and xmltodict modules if you don't have it yet
# import json module and xmltodict module provided by python

import json
import xmltodict

# open the input xml file and read
# data in form of python dictionary
# using xmltodict module
with open("test.xml") as xml_file:
	
	data_dict = xmltodict.parse(xml_file.read())
	xml_file.close()
	
	# generate the object using json.dumps()
	# corresponding to json data
	
	json_data = json.dumps(data_dict, indent=4)
	
	# Write the json data to output json file called output
	with open("xml_converted.json", "w") as json_file:
		json_file.write(json_data)
		json_file.close()
xml_file.close()


## 04 project
    At work, there is a tool to generate synthetic data. The data generated is in JSON format and needs to be transformed into CSV format for a specific team. Write a python script that can take a JSON file and construct a CSV file from it. Let's work with the JSON file called "xml_converted.json" as an example.

    # Python program to convert
# JSON file to CSV


import json
import csv
from os import sep


# Opening JSON file and loading the data
# into the variable data
with open('xml_converted.json') as json_file:
	data = json.load(json_file)    ## Create a dict called data with the json content

# create list of catalog 
catalog_book = data['catalog']['book']

# now we will open a csv file for writing
data_file = open('json_converted.csv', 'w')

# create the csv writer object
csv_writer = csv.writer(data_file)

# Counter variable used for writing
# headers to the CSV file
count = 0

for element in catalog_book:
	if count == 0:
		# Writing headers of CSV file
		header = element.keys()
		csv_writer.writerow(header)
		count += 1

	# Writing data of CSV file
	csv_writer.writerow(element.values())

data_file.close()


## 05 project
  The dev team is using a script to inventory instance infos from aws using the boto3 module. (the script is querying all instances with tag {environment: dev} this value is hard coded in the script. please modify the script so the qa team and eventually the subsequent team can use it to do the same.

  #!/usr/bin/python
'''
This script starts all instances with a specific tag.
'''

import boto3

#ec2_client=boto3.client('ec2')
ec2_resource = boto3.resource('ec2')

def instances_find(name, value):
    '''
    Finds instance id's based on tags.
    Returns a list of instances found.
    '''
    list_instances = []
    # filter based on tags
    filters =[
        {
        'Name': name,
        'Values': [
            value,
            ]
        },
    ]
    instances = ec2_resource.instances.filter(Filters=filters)
    
    
    for instance in instances:
        
        # for each instance, append to list
        list_instances.append(instance)
        #list_instances.append(instance.describe_instances())

    return list_instances

def show_instances(instances):
    header = "instance.id\t\t instance_type\t\t instance_image.id"
    print(header)
    for instance in instances:
        instance_details = f"{instance.id}\t {instance.instance_type} \t\t{instance.image_id}"
        print(instance_details)


# def instances_start(list):
    #'''
    #Starts instances defined in the list.
    #'''
    # ec2_client.start_instances(InstanceIds=list)

# enter tag name and value
tag_name = 'tag:environment'
tag_value = 'dev'


# find instances
ec2_list = instances_find(tag_name, tag_value)


#show instances
show_instances(ec2_list)


## 06 project
     At work, we have an internal application running on PostgreSQL, and we need a python script that will take a backup of the database and upload it to an s3 bucket hourly or daily.
The script is below:
Before executing the below script, you have to set Database credentials, AWS Access key credentials and backup path.

import os
import sys
import subprocess
from optparse import OptionParser
from datetime import datetime
import boto3


DB_USER = 'databaseuser'
DB_NAME = 'databasename'

BACKUP_PATH = r'/webapps/myapp/db_backups'

FILENAME_PREFIX = 'myapp.backup'

# Amazon S3 settings.
AWS_ACCESS_KEY_ID = os.environ['AWS_ACCESS_KEY_ID']
AWS_SECRET_ACCESS_KEY = os.environ['AWS_SECRET_ACCESS_KEY']
AWS_BUCKET_NAME = 'myapp-db-backups'


def main():
    """ 
     The script takes an argument: ‘hourly’ or ‘daily’
    """
    parser = OptionParser()
    parser.add_option('-t', '--type', dest='backup_type',
                      help="Specify either 'hourly' or 'daily'.")

    now = datetime.now()

    filename = None
    (options, args) = parser.parse_args()
    if options.backup_type == 'hourly':
        hour = str(now.hour).zfill(2)
        filename = f'{FILENAME_PREFIX}.h{hour}'
    elif options.backup_type == 'daily':
        day_of_year = str(now.timetuple().tm_yday).zfill(3)
        filename = f'{FILENAME_PREFIX}.d{day_of_year}'
    else:
        parser.error('Invalid argument.')
        sys.exit(1)

    destination = r'%s/%s' % (BACKUP_PATH, filename)

    print (f'Backing up {DB_NAME} database to {destination}')
    ps = subprocess.Popen(  # Execute a child program in a new process
        ['pg_dump', '-U', DB_USER, '-Fc', DB_NAME, '-f', destination],
        stdout=subprocess.PIPE
    )
    output = ps.communicate()[0] # communicate() returns a tuple (stdout_data, stderr_data)
    for line in output.splitlines():
        
        print(line)

    print(f'Uploading {filename} to Amazon S3...')
    upload_to_s3(destination, filename)


def upload_to_s3(source_path, destination_filename):
    """
    Upload a file to an AWS S3 bucket.
    """
    s3_client = boto3.client('s3')

    s3_client.upload_file(
        Filename=source_path,
        Bucket=AWS_BUCKET_NAME,
        Key=destination_filename
    )


if __name__ == '__main__':
    main()


## 07 project
         At work, part of the external audit showed that some of our S3 buckets are exposed and do not have encryption enabled and no bucket policy is applied.
Write a script that checks all the S3 buckets and identifies which are not encrypted and have no bucket policy applied.
The script is below:

import boto3
from botocore.exceptions import ClientError

s3_client = boto3.client('s3')

buckets_list = s3_client.list_buckets()

# get a list of bucket's names
buckets = []
for bucket in buckets_list['Buckets']:
    buckets.append(bucket['Name'])

def get_unencrypted_buckets():
    """ This function get a list of all s3 buckets without Encryption """
    _unencrypted_buckets=[]
    encryptionError='ServerSideEncryptionConfigurationNotFoundError'
    for bucket in buckets:
        try:
            # bucket has encryption enable
            _bucket_enc_response = s3_client.get_bucket_encryption(Bucket=bucket) 
            rules = _bucket_enc_response['ServerSideEncryptionConfiguration']['Rules']
            print(f"Bucket: {bucket}, Encryption: {rules}")
        except ClientError as e:
            if e.response['Error']['Code'] == encryptionError: # unencrypted bucket error
                print(f"Bucket: {bucket}, no server-side encryption")
                _unencrypted_buckets.append(bucket) # add unencrypted bucket in a list
            else: # any other type of error
                print(f"Bucket: {bucket}, unexpected error for encryption check: {e}")
    return _unencrypted_buckets

def get_nopolicy_buckets():
    """ This function get a list of all s3 buckets without policy"""
    _no_policy_buckets=[]
    policyError= 'NoSuchBucketPolicy'
    for bucket in buckets:
        try:
            # bucket has policy
            policy_status=s3_client.get_bucket_policy_status(Bucket=bucket)
            print(f"Bucket: {bucket}, policy: {policy_status}")
        except ClientError as e:
            if e.response['Error']['Code'] == policyError: # no policy bucket error
                print(f"Bucket: {bucket}, has no policy attached")
                _no_policy_buckets.append(bucket) # add no policy bucket in a list
            else:# any other type of error
                print(f"Bucket: {bucket}, unexpected error for policy check: {e}")
    return _no_policy_buckets

unencrypted_buckets= get_unencrypted_buckets()
nopolicy_buckets= get_nopolicy_buckets()

print("\n ############# List of buckets with no encryption: ########### \n")
if unencrypted_buckets:
    for bucket_name in unencrypted_buckets:
        print(f"\t \t Bucket: {bucket_name} \n")
else:
    print(f"\t \t All Buckets have encryption enable \n")

print("\n ############# List of buckets without policy: ########### \n")

if nopolicy_buckets:
    for bucket_name in nopolicy_buckets:
        print(f"\t \t Bucket: {bucket_name} \n")
else:
    print(f"\t \t All Buckets have policy \n")
    

 ##  08 project
      After finding the s3 buckets that don't have encryption enabled and no bucket policy applied based on project7's script, modify that to fix them accordingly.
The script is below:

     
import boto3
import json
from botocore.exceptions import ClientError

s3_client = boto3.client('s3')

buckets_list = s3_client.list_buckets()


# get a list of bucket's names
buckets = []
for bucket in buckets_list['Buckets']:
    buckets.append(bucket['Name'])

def get_EncryptedFixed_buckets():
    """ This function find all s3 buckets without Encryption and fixed them, 
    then return the list of fixed buckets """
    unencrypted_buckets_fixed=[]
    encryptionError='ServerSideEncryptionConfigurationNotFoundError'
    for bucket in buckets:
        try:
            _bucket_enc_response = s3_client.get_bucket_encryption(Bucket=bucket)
            rules = _bucket_enc_response['ServerSideEncryptionConfiguration']['Rules']
            print(f"Bucket: {bucket}, Encryption: {rules}")
        except ClientError as e:
            if e.response['Error']['Code'] == encryptionError:
                print(f"Bucket: {bucket}, no server-side encryption")
                # put encryption on the bucket
                s3_client.put_bucket_encryption(
                    Bucket= bucket,
                    ServerSideEncryptionConfiguration={
                        'Rules': [
                            {'ApplyServerSideEncryptionByDefault': {'SSEAlgorithm': 'AES256'}},
                        ]
                    }
                )
                print(f"Encryption fixed on {bucket}")
                unencrypted_buckets_fixed.append(bucket)
            else:
                print(f"Bucket: {bucket}, unexpected error for encryption check: {e}")
    return unencrypted_buckets_fixed


def set_bucket_policy(bucket_name):
    """ This function is used to attach a policy to a bucket"""
    ### change the IAM_USER_ARN in the bucket_policy
    bucket_policy={
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "VisualEditor0",
                "Effect": "Allow",
                "Action": "s3:*",
                "Resource": f"arn:aws:s3:::{bucket_name}/*",
                "Principal": {
                    "AWS": [
                        "<IAM_USER_ARN>",
                    ]
                },
            }
        ]
    }
    bucket_policy=json.dumps(bucket_policy)
    response = s3_client.put_bucket_policy(Bucket=bucket_name, Policy=bucket_policy)
    return response

def get_NoPolicyFixed_buckets():
    """ This function find all s3 buckets with no policy and attach policy to them, 
    then return the list of fixed buckets """
    _no_policy_buckets_fixed=[]
    policyError= 'NoSuchBucketPolicy'
    for bucket in buckets:
        try:
            policy_status=s3_client.get_bucket_policy_status(Bucket=bucket)
            print(f"Bucket: {bucket}, policy: {policy_status}")
        except ClientError as e:
            if e.response['Error']['Code'] == policyError:
                print(f"Bucket: {bucket}, has no policy attached")
                try:
                    attached_policy= set_bucket_policy(bucket)
                    print(attached_policy)
                    _no_policy_buckets_fixed.append(bucket)
                    print(f"Policy attached to {bucket}")  
                except ClientError as e:
                    print(f"no policy attached, {e}")
            else:
                print(f"Bucket: {bucket}, unexpected error for policy check: {e}")
    return _no_policy_buckets_fixed

encrypted_buckets= get_EncryptedFixed_buckets()
fixed_policy_buckets= get_NoPolicyFixed_buckets()

print("\n ############# List of buckets with no encryption fixed: ########### \n")
if encrypted_buckets:
    for bucket_name in encrypted_buckets:
        print(f"\t \t Bucket: {bucket_name} \n")
else:
    print(f"\t \t All Buckets are  encrypted \n")

print("\n ############# List of buckets without policy fixed: ########### \n")

if fixed_policy_buckets:
    for bucket_name in fixed_policy_buckets:
        print(f"\t \t Bucket: {bucket_name} \n")
else:
    print(f"\t \t All Buckets have policy \n")
    

## 09 project
     The script in project8 is running locally, Configure it to run periodically (every week) with lambda function and email the security team with any findings.
The script is below:
Attach policies for S3 and SES to the role of your lambda function in AWS.

 import boto3
import json
from botocore.exceptions import ClientError

def lambda_handler(event, context):
    s3_client = boto3.client('s3')

    buckets_list = s3_client.list_buckets()

    # get a list of bucket's names
    buckets = []
    for bucket in buckets_list['Buckets']:
        buckets.append(bucket['Name'])
    AWS_REGION='ap-south-1'
    def get_EncryptedFixed_buckets():
        """ This function find all s3 buckets without Encryption and fixed them, 
        then return the list of fixed buckets """
        unencrypted_buckets_fixed=[]
        encryptionError='ServerSideEncryptionConfigurationNotFoundError'
        for bucket in buckets:
            try:
                _bucket_enc_response = s3_client.get_bucket_encryption(Bucket=bucket)
                rules = _bucket_enc_response['ServerSideEncryptionConfiguration']['Rules']
                print(f"Bucket: {bucket}, Encryption: {rules}")
            except ClientError as e:
                if e.response['Error']['Code'] == encryptionError:
                    print(f"Bucket: {bucket}, no server-side encryption")
                    # put encryption on the bucket
                    s3_client.put_bucket_encryption(
                        Bucket= bucket,
                        ServerSideEncryptionConfiguration={
                            'Rules': [
                                {'ApplyServerSideEncryptionByDefault': {'SSEAlgorithm': 'AES256'}},
                            ]
                        }
                    )
                    print(f"Encryption fixed on {bucket}")
                    unencrypted_buckets_fixed.append(bucket)
                else:
                    print(f"Bucket: {bucket}, unexpected error for encryption check: {e}")
        return unencrypted_buckets_fixed


    def set_bucket_policy(bucket_name):
        """ This function is used to attach a policy to a bucket"""
        ### change the IAM_USER_ARN in the bucket_policy
        bucket_policy={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Sid": "VisualEditor0",
                    "Effect": "Allow",
                    "Action": "s3:*",
                    "Resource": f"arn:aws:s3:::{bucket_name}/*",
                    "Principal": {
                        "AWS": [
                            "<SET YOUR IAM_USER_ARN>",
                        ]
                    },
                }
            ]
        }
        bucket_policy=json.dumps(bucket_policy)
        response = s3_client.put_bucket_policy(Bucket=bucket_name, Policy=bucket_policy)
        return response

    def get_NoPolicyFixed_buckets():
        """ This function find all s3 buckets with no policy and attach policy to them, 
        then return the list of fixed buckets """
        _no_policy_buckets_fixed=[]
        policyError= 'NoSuchBucketPolicy'
        for bucket in buckets:
            try:
                policy_status=s3_client.get_bucket_policy_status(Bucket=bucket)
                print(f"Bucket: {bucket}, policy: {policy_status}")
            except ClientError as e:
                if e.response['Error']['Code'] == policyError:
                    print(f"Bucket: {bucket}, has no policy attached")
                    try:
                        attached_policy= set_bucket_policy(bucket)
                        print(attached_policy)
                        _no_policy_buckets_fixed.append(bucket)
                        print(f"Policy attached to {bucket}")  
                    except ClientError as e:
                        print(f"no policy attached, {e}")
                else:
                    print(f"Bucket: {bucket}, unexpected error for policy check: {e}")
        return _no_policy_buckets_fixed

    encrypted_buckets= get_EncryptedFixed_buckets()
    fixed_policy_buckets= get_NoPolicyFixed_buckets()
    buckets_fixed=list(set(encrypted_buckets+fixed_policy_buckets))

    # send the email to security team
    def send_mail(): 
        # set a verified email address of security team
        RECIPIENT = ["<SET A VERIFIED EMAIL OF SECURITY TEAM>"]
        # set your verified sender email address
        SENDER = "<SET A VERIFIED SENDER EMAIL>"
        ses_client = boto3.client('ses')
        SUBJECT = "List of buckets that have public access "
        BODY_TEXT = (f"""
        Hello Team,           
        Find below vulnerable S3 bucket(s):
        Bucket_name: {buckets_fixed}
        Thanks and regards 
        """)           
        CHARSET = "UTF-8"
        
        try:
            response = ses_client.create_configuration_set(
                ConfigurationSet={
                    'Name': 'my-config-set'
                }
            )   
        except Exception as e:
            print('Configuration set exists:' + e.response['Error']['Message'])
        else:
            print(f'Configuration set creation error !!! Please check your configuration set')
        try:
            response = ses_client.send_email(
                Destination={
                    'ToAddresses': RECIPIENT,
                },
                Message={
                    'Body': {
                        'Text': {
                            'Charset': CHARSET,
                            'Data': BODY_TEXT,
                        },
                    },
                    'Subject': {
                        'Charset': CHARSET,
                        'Data': SUBJECT,
                    },
                },
                Source=SENDER,
                ConfigurationSetName='my-config-set',
            )
        except ClientError as e:
            print(e.response['Error']['Message'])
        else:
            print(f"Email successfully sent! Message ID: {response['MessageId']}")
            
    # send mail if buckets_fixed is not empty
    if buckets_fixed:
        send_mail()
    else:
        print("All the Buckets are good !!!")    
    # send mail if buckets_fixed is not empty
    if buckets_fixed:
        send_mail()
    else:
        print("All the Buckets are good !!!")  


  ## 10 project
             import boto3, datetime
from datetime import date
from botocore.exceptions import ClientError

AWS_REGION= "us-east-1"

email_list = []

iam = boto3.client('iam', region_name=AWS_REGION)

def send_mail(email_list):
    # emails in email_list must be verified by AWS SES
    RECIPIENTS = email_list
    # set your verified email address from AWS SES
    SENDER = "<SET YOUR SENDER EMAIL>"
    SUBJECT = "WARNING!!! IAM Access Key Rotation"
    BODY_TEXT = ("Your IAM Access Key need to be rotated immediately as it is 3 months or older.\n" 
                "If not, it will be deactivated shortly.")           
    CHARSET = "UTF-8"
    ses_client = boto3.client('ses', region_name=AWS_REGION)
    # verify if the configuration set is created, if not then create it
    try:
        response = ses_client.create_configuration_set(
            ConfigurationSet={
                'Name': 'my-config-set'
            }
        )   
    except Exception as e:
        print('Configuration set exists:' + e.response['Error']['Message'])
    else:
        print(f'Configuration set creation error !!! Please check your configuration set')
    # send email
    try:
        response = ses_client.send_email(
            Destination={
                'ToAddresses': RECIPIENTS,
            },
            Message={
                'Body': {
                    'Text': {
                        'Charset': CHARSET,
                        'Data': BODY_TEXT,
                    },
                },
                'Subject': {
                    'Charset': CHARSET,
                    'Data': SUBJECT,
                },
            },
            Source=SENDER,
            ConfigurationSetName='my-config-set',
        )
    except ClientError as e:
        print(e.response['Error']['Message'])
    else:
        print(f"Email sent! Message ID: {response['MessageId']}")

for user in iam.list_users()['Users']: # check for all iam users 
    # get a list of access keys for a user
    userKeys = iam.list_access_keys(UserName=user['UserName'])
    for keyValue in userKeys['AccessKeyMetadata']:
        # check if access key is active
        if keyValue['Status'] == 'Active':
            currentdate = date.today()
            active_days = currentdate - keyValue['CreateDate'].date()
            userTags = iam.list_user_tags(UserName=user['UserName'])
            if (active_days >= datetime.timedelta(days=90)):
                # get the list of email from tags as key:value
                email_tags = list(filter(lambda tag: tag['Key'] == 'email', userTags['Tags']))
                # make a list of email from tags 
                for email_tag in email_tags:
                    email = email_tag['Value']
                    email_list.append(email)
                    print(email)
                print(f"Access key: {keyValue[ 'AccessKeyId']} of {keyValue['UserName']} need to be rotated")
                # deactivate keys 
                #iam.update_access_key(UserName=keyValue['UserName'], AccessKeyId=keyValue['AccessKeyId'], Status='Inactive')
            else:
                print(f"Access key: {keyValue[ 'AccessKeyId']} of {keyValue['UserName']} have been rotated")
        else:
            print(f"The Access key : {keyValue[ 'AccessKeyId']}  of {user} is inactive !!!")

# to remove duplicated emails
email_unique = list(set(email_list))
if len(email_unique) >= 1:
    send_mail(email)
else:
    print('There is no email address in the tags or all access keys have been rotated')


  ## 11 project
        Write a script that will check if all AWS users have been created correctly as far as password, MFA set up and tag. Then, delete incorrect users and notify the security team by email. This script should run every day for security purposes.
Attach policies for IAM and SES to the role of your lambda function in AWS.
The script is below:

   import boto3
from botocore.exceptions import ClientError

iam_client = boto3.client('iam')
incorrect_users=[]
users_deleted=[]

def lambda_handler(event, context):

    def list_incorrect_users():
        """ function to get the list of incorrect users """
        iam_users = []
        users = iam_client.list_users()
        # get all IAM user names
        for i in users['Users']:
            iam_users.append(i['UserName'])

        for user_name in iam_users:
            try:
                # Get MFA devices associated with the user
                mfa_devices = iam_client.list_mfa_devices(UserName=user_name)
                mfa_count = len(mfa_devices['MFADevices'])
                
                # Get the list of tags attached to the user
                user_tags = iam_client.list_user_tags(UserName=user_name)
                tags_list = user_tags['Tags']
                
                # Check if the user has a login profile (password)
                iam_client.get_login_profile(UserName=user_name)
                login_profile_exists = True
            except ClientError as e:
                login_profile_exists = False
            
            if not login_profile_exists and mfa_count == 0 and not tags_list:
                incorrect_users.append(user_name)
        return incorrect_users
    

    def send_mail(user_list):
        """ function to send the list of incorrect users to the security team """
        # set a verified email address for security team 
        RECIPIENT = ["<SET A VERIFIED EMAIL OF SECURITY TEAM>"]
        # set your verified sender email address
        SENDER = "<SET A VERIFIED EMAIL OF SENDER>"
        SUBJECT = "Notification: Deletion of Incorrect IAM Users"
        BODY_TEXT = (f"""
        Hello Security team,
         
        This email is to inform you that the following IAM users have been identified as incorrect and have been deleted from the AWS account.
        The deletion was necessary because these users were created without meeting the required security configurations, including a password, MFA, and user tags.
                     
        Below is the list of deleted users:
    
        {', '.join(user_list)}

        If you have any questions or need further details, please do not hesitate to contact the IT department.

        Best regards.
        """)           
        CHARSET = "UTF-8"
        # set your AWS region
        AWS_REGION="<SET YOUR AWS REGION>"
        ses_client = boto3.client('ses', region_name=AWS_REGION)
        # verify if the configuration set is created, if not then create it
        try:
            response = ses_client.create_configuration_set(
                ConfigurationSet={
                    'Name': 'my-config-set'
                }
            )   
        except Exception as e:
            print('Configuration set exists:' + e.response['Error']['Message'])
        else:
            print(f'Configuration set creation error !!! Please check your configuration set')
        # send email
        try:
            response = ses_client.send_email(
                Destination={
                    'ToAddresses': RECIPIENT,
                },
                Message={
                    'Body': {
                        'Text': {
                            'Charset': CHARSET,
                            'Data': BODY_TEXT,
                        },
                    },
                    'Subject': {
                        'Charset': CHARSET,
                        'Data': SUBJECT,
                    },
                },
                Source=SENDER,
                ConfigurationSetName='my-config-set',
            )
        except ClientError as e:
            print(f"Error sending email: {e.response['Error']['Message']}")
        else:
            print(f"Email sent! Message ID: {response['MessageId']}")

    def delete_user_items(user):
        """ function to delete all items linked to a user """
        try:
            # Delete access keys
            access_keys = iam_client.list_access_keys(UserName=user)
            for access_key in access_keys['AccessKeyMetadata']:
                iam_client.delete_access_key(UserName=user, AccessKeyId=access_key['AccessKeyId'])
            print(f"Access keys deleted for {user}")

            # Delete signing certificates
            certificates = iam_client.list_signing_certificates(UserName=user)
            for certificate in certificates['Certificates']:
                iam_client.delete_signing_certificate(UserName=user, CertificateId=certificate['CertificateId'])
            print(f"Signing certificates deleted for {user}")

            # Delete SSH public keys
            ssh_keys = iam_client.list_ssh_public_keys(UserName=user)
            for key in ssh_keys['SSHPublicKeys']:
                iam_client.delete_ssh_public_key(UserName=user, SSHPublicKeyId=key['SSHPublicKeyId'])
            print(f"SSH public keys deleted for {user}")

            # Delete service-specific credentials
            service_credentials = iam_client.list_service_specific_credentials(UserName=user)
            for credential in service_credentials['ServiceSpecificCredentials']:
                iam_client.delete_service_specific_credential(UserName=user, ServiceSpecificCredentialId=credential['ServiceSpecificCredentialId'])
            print(f"Service-specific credentials deleted for {user}")

            # Delete inline policies
            policies = iam_client.list_user_policies(UserName=user)
            for policy_name in policies['PolicyNames']:
                iam_client.delete_user_policy(UserName=user, PolicyName=policy_name)
            print(f"Inline policies deleted for {user}")

            # Detach managed policies
            attached_policies = iam_client.list_attached_user_policies(UserName=user)
            for policy in attached_policies['AttachedPolicies']:
                iam_client.detach_user_policy(UserName=user, PolicyArn=policy['PolicyArn'])
            print(f"User managed policies detached for {user}")

            # Remove user from groups
            user_groups = iam_client.list_groups_for_user(UserName=user)
            for group in user_groups['Groups']:
                iam_client.remove_user_from_group(UserName=user, GroupName=group['GroupName'])
            print(f"User removed from groups for {user}")

            # Delete mfa devices
            mfa_devices = iam_client.list_mfa_devices(UserName=user)
            for mfa_device in mfa_devices['MFADevices']:
                iam_client.delete_virtual_mfa_device(SerialNumber=mfa_device['SerialNumber'])
            print(f"MFA devices deleted for {user}")

            # Delete the password (login profile)
            iam_client.delete_login_profile(UserName=user)
            print(f"Password deleted for user: {user}")

        except ClientError as e:
            print(f"Error deleting user items for {user}: {e}")    


    # delete incorrect users
    if __name__ == '__main__':
        incorrect_users_list = list_incorrect_users()
        for user in incorrect_users_list:
            delete_user_items(user)
            iam_client.delete_user(UserName=user)
            users_deleted.append(user)
        send_mail(users_deleted)

   ## 12 project
         EBS Snapshots are a copy of your data at a certain time, and can be used to enable disaster recovery, migrate data across regions and accounts, and improve backup compliance.
Write a script that can automate AWS EBS snapshots and notify the admin via email.
Note: This script needs to be executed twice: the first you will confirm the subscription email, and the second time to send the notification.

    import boto3
from botocore.exceptions import NoCredentialsError, PartialCredentialsError
from datetime import datetime

def create_snapshots_and_notify():

    AWS_REGION = 'us-esat-1'
    ec2_client = boto3.client('ec2', region_name=AWS_REGION)

    snapshots = []

    try:
        # Create snapshots for available volumes
        response = ec2_client.describe_volumes()
        for volume in response['Volumes']:
            volume_id = volume['VolumeId']
            description = f'Snapshot of {volume_id} on {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}'
            
            snapshot = ec2_client.create_snapshot(VolumeId=volume_id, Description=description)
            snapshots.append(snapshot['SnapshotId'])
            print(f"Snapshot created successfully for volume {volume_id}")
            

        # Create a notification topic
        topic_name = 'EBS-Snapshot-notification'
        sns_client = boto3.client("sns", region_name=AWS_REGION)
        topic = sns_client.create_topic(Name=topic_name)
        topic_arn = topic['TopicArn']

        # Subscribe an email to the topic
        # Email needs to be manually confirmed first
        protocol = 'email'
        email = '<SET YOUR ADMIN EMAIL HERE>'

        # Check if the subscription already exists
        subscriptions = sns_client.list_subscriptions_by_topic(TopicArn=topic_arn)['Subscriptions']
        email_exists = any(sub['Endpoint'] == email for sub in subscriptions)

        if not email_exists:
            sns_client.subscribe(
                TopicArn=topic_arn,
                Protocol=protocol,
                Endpoint=email,
                ReturnSubscriptionArn=True
            )

        # Publish a message to the topic via email
        if snapshots:
            message = f"""We successfully created snapshots of your available volumes.
            Here is the list of their IDs: {', '.join(snapshots)}"""
            subject = 'EBS Snapshots'
            response = sns_client.publish(
                TopicArn=topic_arn,
                Message=message,
                Subject=subject,
            )
            message_id = response['MessageId']
            print(f'Message published to topic {topic_arn} with message ID: {message_id}')
        else:
            print('No snapshots were created.')

    except (NoCredentialsError, PartialCredentialsError):
        print("Error: AWS credentials not found or incomplete.")
    except Exception as e:
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    create_snapshots_and_notify()


## 13 project 
       At work, we usually create manually repositories in Github. There is a ticket assigned to you to automatically create, update and list repositories from github using python and requests module.
The script is below
      

import requests
import json

# Define the API endpoint
url = "https://api.github.com"

# Define the headers to include the authorization token
# Link to generate your auth token:
# https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token-classic
token= "<YOUR_AUTH_TOKEN>"
headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

# Define a function to get a list of repositories for a user
def get_repos(username):
    endpoint = f"{url}/users/{username}/repos"
    response = requests.get(endpoint, headers=headers)
    if response.status_code == 200:
        repos = response.json()
        print("\n ############# List of repositories: ########### \n")
        for repo in repos:
            print(f"repo_name:{repo['name']}, repo_url: {repo['html_url']}")
            print("\n ########################################### \n")

    else:
        print(f"Error getting repositories: {response.status_code}")


# Define a function to create a repository for a user
def create_repo(repo_name):
    endpoint = f"{url}/user/repos"
    data = {
        "name": repo_name,
        "private": False,
    }
    response = requests.post(endpoint, headers=headers, data=json.dumps(data))
    if response.status_code == 201:
        print(f"Repository '{repo_name}' created successfully!")
    else:
        print(f"Error creating repository '{repo_name}': {response.status_code}")

# Define a function to update a repository for a user
def update_repo(username, repo_name, description):
    endpoint = f"{url}/repos/{username}/{repo_name}"
    data = {
        "description": description
    }
    response = requests.patch(endpoint, headers=headers, data=json.dumps(data))
    if response.status_code == 200:
        print(f"Repository '{repo_name}' updated successfully!")
    else:
        print(f"Error updating repository '{repo_name}': {response.status_code}")

# Define a function to delete a repository for a user
def delete_repo(username, repo_name):
    endpoint = f"{url}/repos/{username}/{repo_name}"
    response = requests.delete(endpoint, headers=headers)
    if response.status_code == 204:
        print(f"Repository '{repo_name}' deleted successfully!")
    else:
        print(f"Error deleting repository '{repo_name}': {response.status_code}")

# Test the functions
if __name__ == "__main__":
    # Replace <YOUR_USERNAME> with your GitHub username
    username = "<YOUR_USERNAME>"
    
    # Get repositories
    get_repos(username)
        
    # Create a new repository
    repo_name = "test-repo-new"
    create_repo(repo_name)
    
    # Update the repository
    update_repo(username, repo_name, "Updated description")
    
    # Delete the repository
    delete_repo(username, repo_name)


## 14 project
       You work as DevOps Engineer for a company. Your team have built and deployed an application in pre-production. Before pushing the app in production you need to make some tests on it.
The testing process was manual, and your task is to build a Python script that automates web testing using the Selenium WebDriver. The script will be able to log in as a user to the application through the login form and navigate the menu to make sure each page is accessible.
The script below is made based on the geolocation app project of Utrains' Class


  # Prerequisite: install selenium module

from selenium import webdriver
import time
from selenium.webdriver.common.by import By

#open Google Chrome browser  
driver=webdriver.Chrome()

print(f"The test case started")
#maximize the window size
driver.maximize_window()

#delete the cookies  
driver.delete_all_cookies()

#navigate to the URL  
driver.get("http://96.126.113.215:8082/showMyLoginPage")

# get the browser's title
title1= driver.title # title of the login page
print(f"Connecting to {title1} page of Geolocation app")

# identify the username box and enter the value  
elem1 = driver.find_element(by=By.NAME, value="username")
elem1.send_keys("root@utrains.test")

# identify the password box and enter the value  
elem2 = driver.find_element(by=By.NAME, value="password")
elem2.send_keys("root_pass")

# Click on the Log in button
submit_button = driver.find_element(by=By.CSS_SELECTOR, value="button")
submit_button.click()
title2= driver.title # title of the home page

if title1 == title2:
    print("Wrong credentials")
    driver.quit()
    exit()
else:
    print("Connected to website")

time.sleep(5)

# navigate to About us page
elem3= driver.find_element(By.LINK_TEXT, "About")
elem3.click()
time.sleep(5)

# navigate to Departments' page
elem4= driver.find_element(By.LINK_TEXT, "Departments")
elem4.click()
time.sleep(5)

# navigate to Doctors' page
elem5= driver.find_element(By.LINK_TEXT, "Doctors")
elem5.click()
time.sleep(5)

# navigate to Blog page
elem6= driver.find_element(By.LINK_TEXT, "Blog")
elem6.click()
time.sleep(5)

# navigate to Contact page
elem7= driver.find_element(By.LINK_TEXT, "Contact")
elem7.click()
time.sleep(5)

# close the driver
driver.quit()
print("Login to Geolocation app has been successfully completed")



## 15 project
     To maintain a secure and well-organized AWS environment, we need to develop a Python script to automate the cleanup of IAM roles in our AWS environment. The goal is to identify and delete IAM roles that are older than a specified threshold (100 days) using the Boto3 library. This automation will help maintain a secure, efficient, and organized AWS account by regularly removing outdated or unused roles.
The script will become part of our routine maintenance, running on a schedule to automate IAM role cleanup and keep our AWS environment in optimal condition.
The script should:
1. Retrieve all IAM roles in the AWS account.
2. Determine the age of each role based on its creation date.
3. Delete roles that are older than the configured threshold (100 days).
The proposed solution is below:


   

import boto3
import datetime
from botocore.exceptions import ClientError

# Function to delete the IAM role
def delete_iam_role(role_name):
    # create an iam boto3 client
    client = boto3.client('iam')
    try:
        # delete the role by its name
        response = client.delete_role(RoleName=role_name)
        print(f"Role {role_name} deleted successfully")
    except ClientError as e:
        # display the error message if the role can't be deleted
        print(f"Error deleting role {role_name}:{e.response['Error']['Message']}")
    
    

# Function to get the age of the role

def get_role_age(role_name):
    # Create an IAM boto3 client
    client = boto3.client('iam')
    try:
        # Retrieve role information
        response = client.get_role(RoleName=role_name)
    except ClientError as e:
        # Display an error message if role details can't be retrieved
        print(f"Error retrieving role {role_name}:{e.response['Error']['Message']}")
        return None  # Return None if there's an error

    # Get the role creation date and current date    
    role_creation_date = response['Role']['CreateDate']
    current_date = datetime.datetime.now(datetime.timezone.utc)
    # compute the role's age
    age = (current_date - role_creation_date).days
    
    return age

# Function to get the list of roles
def get_role_list():
    # Create an IAM boto3 client
    client = boto3.client('iam')
    try:
        # List all roles
        response = client.list_roles()
    except ClientError as e:
        # Display an error message if roles can't be listed
        print(f"Error listing roles: {e.response['Error']['Message']}")
        return []  # Return an empty list if there's an error
    
    # Extract role names
    role_list = [role['RoleName'] for role in response['Roles']]
    return role_list
    
def main():
    """
    Main function to check IAM roles and delete those older than 100 days.
    """
    # Get the list of all roles
    roles = get_role_list()
    # Iterate over each role
    for role in roles:
        # Get the age of the role
        age = get_role_age(role)
        # If age is greater than 100 days, delete the role
        if age is not None and age > 100:
            delete_iam_role(role)

if __name__ == '__main__':
    main()

## 16 project
        Project 7: Python Script to List S3 Buckets with No Encryption Enabled and No Bucket Policy Applied
At work, part of the external audit showed that some of our S3 buckets are exposed and do not have encryption enabled, and no bucket policy is applied.
Write a script that checks all the S3 buckets and identifies which are not encrypted and have no bucket policy applied.
  


  ## projects 16 
         Write a Python script to check on a server if ports from a given list of ports are open or closed
The goal of this project is, to determine for a given list of ports, those who are open or closed on a server. Then send a check report to the admin via email.
To achieve this goal, we have to go through the following steps:
Step 1: Install modules needed for this script
We need to install some Python modules to be able to execute this script. To install these modules, we use the pip3 command.
Install the socket module used to check the connection to the server with a specific port.
pip3 install socket
Install the boto3 module used to manage AWS services like AWS SES to send emails to the admin
pip3 install boto3
Step 2: Verify your email with AWS SES (Simple Email Service) and boto3
Let’s create a small script to verify an input email in VS code:
cd ~
mkdir Utrains_python_scripts
cd Utrains_python_scripts
code verify_email_ses.py
Then copy the following script and paste it inside that file.
import boto3
from botocore.exceptions import ClientError

email=str(input("enter your email address: "))
# set your aws region
AWS_REGION="<AWS_REGION>"
ses_client= boto3.client('ses', region_name=AWS_REGION)
# get a list of verified email for this region
verified_email_list= ses_client.list_verified_email_addresses()
if email in verified_email_list['VerifiedEmailAddresses']:
    # display this message if the email is verified in this region
    print(f"{email} is already verified in this region.")
else:
    print(f"Amazon SES is verifying your email: {email}.")
    # send a verfication mail to the email address an create the identity in AWS SES
    ses_client.verify_email_identity(EmailAddress=email)
    print("check your inbox and click into the link to confirm it")
Change the AWS_REGION in the script, then save it.
Run the script with the following command
python3 verify_email_ses.py
During the execution of the script, enter your email address.

Here’s the email that was sent from AWS to verify the email. Click on the link in the email to verify it.

When the verification is done, you get this message.

Step 3: Create and execute our Python script
Now, let’s create our Python script in the VS code terminal:
cd ~
cd Utrains_python_scripts
code check_server_ports.py
Then copy the following code and paste it inside that file.
import socket
import boto3
from botocore.exceptions import ClientError

# specify the list of ports that you want to check on the server
ports = [80, 8080, 8081, 8082,8085]

open_ports=[]
closed_ports=[]


def is_running(host,port):

    """ This function attempts to connect to the given server using a socket.
            Returns: Whether or not it was able to connect to the server. """
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.connect((host, port))
        return True
    except socket.error:
        return False

# this function is able to check the connection status of each port of the list of ports.
def test_port_server(host):
    for port in ports:
        if is_running(host,port):
            print(f"{host}:{port} is running!")
            open_ports.append(port)
        else:
            print(f'There is a problem with {host}:{port}')
            closed_ports.append(port)

def send_mail():
    """ function to send the check report to the admin """
    # set a verified email address of the admin 
    RECIPIENT = ["<SET A VERIFIED EMAIL OF THE ADMIN>"]
    # set your verified sender email address 
    SENDER = "<SET A VERIFIED EMAIL OF SENDER>"
    SUBJECT = "Check report of ports: {} on the server {} ".format(ports,server)
    if len(open_ports) == 0:
        BODY_TEXT = (f"""
        Hello admin, 
        This mail is to make a quick report of specified ports: {ports} on the server: {server}
        There are no open ports on the server.
        List of closed ports: {closed_ports}
        """)
    elif len(closed_ports) == 0:
        BODY_TEXT = (f"""
        Hello admin, 
        This mail is to make a quick report of specified ports: {ports} on the server: {server}
        List of open ports: {open_ports}
        There are no closed ports on the server.
        """)
    else:
        BODY_TEXT = (f"""
        Hello admin, 
        This mail is to make a quick report of specified ports: {ports} on the server: {server}
        List of open ports: {open_ports}
        List of closed ports: {closed_ports}
        """)           
    CHARSET = "UTF-8"
    # set your aws region <SET YOUR AWS REGION>
    AWS_REGION="<AWS REGION>"
    ses_client = boto3.client('ses', region_name=AWS_REGION)
    try:
        response = ses_client.send_email(
            Destination={
                'ToAddresses': RECIPIENT,
            },
            Message={
                'Body': {
                    'Text': {
                        'Charset': CHARSET,
                        'Data': BODY_TEXT,
                    },
                },
                'Subject': {
                    'Charset': CHARSET,
                    'Data': SUBJECT,
                },
            },
            Source=SENDER,
        )
    except ClientError as e:
        print(e.response['Error']['Message'])
    else:
        print(f"Email sent! Message ID: {response['MessageId']}")

if __name__== '__main__':
    server=str(input('Enter the address of your server: '))
    test_port_server(server)
    send_mail()
Modify the script by editing:
RECIPIENT: the verified email of admin.
SENDER: Your email was verified previously by AWS SES.
AWS_REGION: Your AWS region.
Important notes:
We will use the email that we verified previously as RECIPIENT and SENDER.
We set a list of ports in the script for the test, that can be changed depending on the purpose.
Execution of the script
To execute this script, use this command in the terminal:
python3 check_server_ports.py
During the execution of the script, enter the address of the server. Let’s use utrains.org
This script will take some minutes to run completely.

An email will be sent to the verified email address of the admin.


        
          

